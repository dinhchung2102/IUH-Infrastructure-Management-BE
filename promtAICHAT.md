# ü§ñ PROMPT CHO AGENT IDE - TRI·ªÇN KHAI H·ªÜ TH·ªêNG AI RAG

## üìã CONTEXT

T√¥i c√≥ h·ªá th·ªëng qu·∫£n l√Ω c∆° s·ªü v·∫≠t ch·∫•t (CSVC) cho tr∆∞·ªùng ƒë·∫°i h·ªçc, s·ª≠ d·ª•ng NestJS + MongoDB. C·∫ßn t√≠ch h·ª£p AI v·ªõi:

- **Database**: MongoDB (ƒë√£ c√≥ s·∫µn)
- **Vector DB**: Qdrant (self-hosted) - cho vector embeddings
- **LLM Provider**: Google Gemini API
- **Queue**: BullMQ + Redis (ƒë√£ c√≥ s·∫µn Redis trong project)
- **Cache**: Redis (ƒë√£ c√≥ s·∫µn)

## üéØ Y√äU C·∫¶U CHUNG

√Åp d·ª•ng best practices:

- TypeScript strict mode
- Dependency Injection pattern
- Error handling ƒë·∫ßy ƒë·ªß
- Config t·ª´ environment variables
- C√≥ comment ti·∫øng Vi·ªát gi·∫£i th√≠ch logic
- S·ª≠ d·ª•ng Mongoose cho MongoDB operations

---

## üì¶ B∆Ø·ªöC 1: C√ÄI ƒê·∫∂T DEPENDENCIES

```bash
# C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt cho AI module
npm install @google/generative-ai @qdrant/js-client-rest bullmq ioredis
npm install --save-dev @types/ioredis

# N·∫øu ch∆∞a c√≥ Mongoose
npm install @nestjs/mongoose mongoose
npm install --save-dev @types/mongoose
```

---

## üèóÔ∏è B∆Ø·ªöC 2: T·∫†O C·∫§U TR√öC MODULE

T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c sau trong NestJS:

```
src/
‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îú‚îÄ‚îÄ ai.module.ts
‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.controller.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classification.controller.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ search.controller.ts
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini.service.ts           # Wrapper cho Gemini API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qdrant.service.ts           # Vector DB operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag.service.ts              # RAG core logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classification.service.ts   # Ph√¢n lo·∫°i s·ª± c·ªë
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing.service.ts         # Index documents
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sync.service.ts             # ƒê·ªìng b·ªô MongoDB ‚Üî Qdrant
‚îÇ   ‚îú‚îÄ‚îÄ queues/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing.processor.ts       # BullMQ worker
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ indexing.queue.ts
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai-metadata.schema.ts       # Schema cho AI metadata
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ indexed-document.schema.ts  # Schema tracking indexed docs
‚îÇ   ‚îú‚îÄ‚îÄ dtos/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.dto.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classify-incident.dto.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ search.dto.ts
‚îÇ   ‚îî‚îÄ‚îÄ interfaces/
‚îÇ       ‚îú‚îÄ‚îÄ document.interface.ts
‚îÇ       ‚îî‚îÄ‚îÄ classification.interface.ts
‚îú‚îÄ‚îÄ incidents/
‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îÇ       ‚îî‚îÄ‚îÄ incident.schema.ts          # Update schema v·ªõi AI fields
‚îú‚îÄ‚îÄ cache/
‚îÇ   ‚îú‚îÄ‚îÄ cache.module.ts
‚îÇ   ‚îî‚îÄ‚îÄ cache.service.ts
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ ingest/
        ‚îú‚îÄ‚îÄ ingest-documents.ts
        ‚îî‚îÄ‚îÄ chunk-utils.ts
```

---

## üóÑÔ∏è B∆Ø·ªöC 3: MONGOOSE SCHEMAS

### **File: `src/incidents/schemas/incident.schema.ts`**

C·∫≠p nh·∫≠t Incident schema v·ªõi AI-related fields:

```typescript
import { Prop, Schema, SchemaFactory } from '@nestjs/mongoose';
import { Document, Types } from 'mongoose';

@Schema({ timestamps: true })
export class Incident extends Document {
  @Prop({ required: true })
  description: string;

  @Prop({ required: true })
  location: string;

  @Prop({
    type: String,
    enum: [
      'DIEN',
      'NUOC',
      'MANG',
      'NOI_THAT',
      'DIEU_HOA',
      'VE_SINH',
      'AN_NINH',
      'KHAC',
    ],
  })
  category: string;

  @Prop({ type: String, enum: ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW'] })
  priority: string;

  @Prop({ type: String })
  vectorId: string; // Link t·ªõi Qdrant point ID (th∆∞·ªùng d√πng _id.toString())

  @Prop({ type: [{ type: Types.ObjectId, ref: 'Staff' }] })
  assignedStaff: Types.ObjectId[];

  @Prop({
    type: String,
    enum: ['PENDING', 'IN_PROGRESS', 'RESOLVED', 'CLOSED'],
    default: 'PENDING',
  })
  status: string;

  @Prop({ type: Object })
  aiMetadata: {
    classificationScore: number;
    suggestedStaffSkills: string[];
    estimatedDuration: number;
    reasoning: string;
    autoClassified: boolean;
    classifiedAt: Date;
  };

  @Prop({ type: [String] })
  images: string[];

  @Prop({ type: Types.ObjectId, ref: 'User' })
  reportedBy: Types.ObjectId;

  @Prop({ type: Date })
  resolvedAt?: Date;
}

export const IncidentSchema = SchemaFactory.createForClass(Incident);

// Indexes
IncidentSchema.index({ category: 1, status: 1 });
IncidentSchema.index({ priority: -1, createdAt: -1 });
IncidentSchema.index({ vectorId: 1 });
IncidentSchema.index({ 'aiMetadata.classificationScore': -1 });
```

### **File: `src/ai/schemas/indexed-document.schema.ts`**

Track c√°c documents ƒë√£ ƒë∆∞·ª£c indexed v√†o Qdrant:

```typescript
import { Prop, Schema, SchemaFactory } from '@nestjs/mongoose';
import { Document } from 'mongoose';

@Schema({ timestamps: true })
export class IndexedDocument extends Document {
  @Prop({ required: true, unique: true })
  vectorId: string; // ID trong Qdrant

  @Prop({ required: true })
  sourceType: string; // 'incident', 'sop', 'faq', 'facility', 'policy'

  @Prop({ required: true })
  sourceId: string; // MongoDB _id c·ªßa document g·ªëc

  @Prop({ required: true })
  content: string; // Text ƒë√£ ƒë∆∞·ª£c indexed

  @Prop({ type: Object })
  metadata: {
    title?: string;
    url?: string;
    page?: number;
    category?: string;
    tags?: string[];
    lastModified?: Date;
  };

  @Prop({ type: Number, default: 768 })
  embeddingDimension: number;

  @Prop({ type: Date })
  lastSyncedAt: Date;

  @Prop({ type: Boolean, default: true })
  isActive: boolean;
}

export const IndexedDocumentSchema =
  SchemaFactory.createForClass(IndexedDocument);

// Indexes
IndexedDocumentSchema.index({ sourceType: 1, sourceId: 1 });
IndexedDocumentSchema.index({ vectorId: 1 }, { unique: true });
IndexedDocumentSchema.index({ isActive: 1, sourceType: 1 });
```

---

## üîß B∆Ø·ªöC 4: IMPLEMENT GEMINI SERVICE

**File: `src/ai/services/gemini.service.ts`**

T·∫°o service wrapper cho Gemini API v·ªõi c√°c y√™u c·∫ßu:

1. Support c·∫£ chat completion v√† embedding
2. C√≥ retry logic khi API fail
3. Track token usage
4. Cache embedding results (Redis)
5. Handle rate limiting

Features c·∫ßn c√≥:

```typescript
@Injectable()
export class GeminiService {
  // Kh·ªüi t·∫°o Gemini client
  constructor(
    @Inject(CACHE_MANAGER) private cacheManager: Cache,
    private configService: ConfigService,
  ) {}

  // Generate single embedding
  async generateEmbedding(text: string): Promise<number[]>;

  // Batch generate embeddings (t·ªëi ∆∞u cost)
  async batchGenerateEmbeddings(texts: string[]): Promise<number[][]>;

  // Chat completion
  async chatCompletion(
    messages: Array<{ role: string; content: string }>,
    options?: { temperature?: number; maxTokens?: number },
  ): Promise<{
    content: string;
    usage: { promptTokens: number; completionTokens: number };
  }>;

  // RAG-specific chat v·ªõi context
  async chatWithContext(
    query: string,
    context: string,
    systemPrompt: string,
  ): Promise<{ answer: string; usage: any }>;

  // Retry logic v·ªõi exponential backoff
  private async retryWithBackoff<T>(
    fn: () => Promise<T>,
    maxRetries = 3,
  ): Promise<T>;
}
```

Config:

- Model embedding: `text-embedding-004` (768 dimensions)
- Model chat: `gemini-2.0-flash-exp` (nhanh, r·∫ª) ho·∫∑c `gemini-1.5-pro` (th√¥ng minh h∆°n)
- Temperature: 0.3 cho RAG, 0.7 cho chat th∆∞·ªùng
- Cache embedding trong Redis: TTL 7 ng√†y

---

## üóÑÔ∏è B∆Ø·ªöC 5: IMPLEMENT QDRANT SERVICE

**File: `src/ai/services/qdrant.service.ts`**

T·∫°o service qu·∫£n l√Ω Qdrant v·ªõi:

1. Initialize collection v·ªõi config:
   - Collection name: `iuh_csvc_knowledge`
   - Vector size: 768 (theo Gemini embedding)
   - Distance: Cosine
2. CRUD operations:
   - `upsertDocument(id, vector, payload)`: Insert/update vector
   - `search(query, options)`: Search v·ªõi filter support
   - `deleteDocument(id)`: X√≥a vector
   - `getDocument(id)`: L·∫•y document theo ID
   - `batchUpsert(points[])`: Batch insert cho performance
3. Collection management:
   - `createCollection()`: T·∫°o collection n·∫øu ch∆∞a c√≥
   - `collectionExists()`: Check collection
   - `getCollectionInfo()`: Th√¥ng tin collection
4. Health check connection

```typescript
@Injectable()
export class QdrantService {
  private client: QdrantClient;
  private readonly collectionName = 'iuh_csvc_knowledge';

  constructor(private configService: ConfigService) {
    this.client = new QdrantClient({
      url: this.configService.get('QDRANT_URL'),
    });
  }

  async onModuleInit() {
    await this.ensureCollection();
  }

  async ensureCollection(): Promise<void> {
    // T·∫°o collection n·∫øu ch∆∞a t·ªìn t·∫°i
  }

  async upsertDocument(
    id: string,
    vector: number[],
    payload: Record<string, any>,
  ): Promise<void>;

  async search(
    queryVector: number[],
    options: {
      limit?: number;
      scoreThreshold?: number;
      filter?: Record<string, any>;
    },
  ): Promise<Array<{ id: string; score: number; payload: any }>>;

  async deleteDocument(id: string): Promise<void>;

  async batchUpsert(
    points: Array<{ id: string; vector: number[]; payload: any }>,
  ): Promise<void>;
}
```

---

## üîÑ B∆Ø·ªöC 6: IMPLEMENT SYNC SERVICE

**File: `src/ai/services/sync.service.ts`**

Service ƒë·ªìng b·ªô MongoDB ‚Üî Qdrant:

```typescript
@Injectable()
export class SyncService {
  constructor(
    private qdrantService: QdrantService,
    private geminiService: GeminiService,
    private indexingQueue: Queue,
    @InjectModel(IndexedDocument.name)
    private indexedDocModel: Model<IndexedDocument>,
  ) {}

  // Sync incident khi m·ªõi t·∫°o
  async onIncidentCreated(incident: Incident): Promise<void> {
    const vectorId = incident._id.toString();

    // Add v√†o queue ƒë·ªÉ x·ª≠ l√Ω async
    await this.indexingQueue.add('index-incident', {
      vectorId,
      sourceType: 'incident',
      sourceId: incident._id.toString(),
      text: `${incident.description}\nƒê·ªãa ƒëi·ªÉm: ${incident.location}`,
      metadata: {
        category: incident.category,
        priority: incident.priority,
        location: incident.location,
        createdAt: incident.createdAt,
      },
    });
  }

  // Sync incident khi update
  async onIncidentUpdated(incident: Incident): Promise<void> {
    // Ch·ªâ update metadata, kh√¥ng re-generate embedding
    const vectorId = incident.vectorId || incident._id.toString();

    await this.qdrantService.updatePayload(vectorId, {
      category: incident.category,
      priority: incident.priority,
      status: incident.status,
      updatedAt: new Date(),
    });

    // Update trong IndexedDocument collection
    await this.indexedDocModel.updateOne(
      { vectorId },
      {
        $set: {
          lastSyncedAt: new Date(),
          'metadata.category': incident.category,
          'metadata.priority': incident.priority,
        },
      },
    );
  }

  // Sync incident khi delete
  async onIncidentDeleted(incidentId: string): Promise<void> {
    const vectorId = incidentId;

    await this.qdrantService.deleteDocument(vectorId);

    await this.indexedDocModel.updateOne(
      { vectorId },
      { $set: { isActive: false } },
    );
  }

  // Bulk sync to√†n b·ªô incidents (d√πng khi kh·ªüi t·∫°o)
  async syncAllIncidents(): Promise<{ indexed: number; failed: number }> {
    // Implementation
  }

  // Re-index document b·ªã l·ªói
  async reindexDocument(vectorId: string): Promise<void> {
    // Implementation
  }
}
```

---

## üß† B∆Ø·ªöC 7: IMPLEMENT RAG SERVICE

**File: `src/ai/services/rag.service.ts`**

Core RAG service v·ªõi flow:

1. Nh·∫≠n query t·ª´ user
2. Generate embedding cho query
3. Search Qdrant (topK=8, minScore=0.7)
4. Assemble context t·ª´ results
5. T·∫°o prompt v·ªõi context
6. G·ªçi Gemini chat completion
7. Tr·∫£ v·ªÅ answer + sources
8. Cache k·∫øt qu·∫£ (30 ph√∫t trong Redis)

```typescript
@Injectable()
export class RAGService {
  constructor(
    private geminiService: GeminiService,
    private qdrantService: QdrantService,
    @Inject(CACHE_MANAGER) private cacheManager: Cache,
  ) {}

  async query(
    query: string,
    options?: {
      sourceTypes?: string[];
      topK?: number;
      minScore?: number;
    },
  ): Promise<RAGSearchResult> {
    // 1. Check cache
    const cacheKey = `rag:${query}:${JSON.stringify(options)}`;
    const cached = await this.cacheManager.get(cacheKey);
    if (cached) return cached;

    // 2. Generate query embedding
    const queryVector = await this.geminiService.generateEmbedding(query);

    // 3. Search Qdrant
    const searchResults = await this.qdrantService.search(queryVector, {
      limit: options?.topK || 8,
      scoreThreshold: options?.minScore || 0.7,
      filter: options?.sourceTypes
        ? { sourceType: { $in: options.sourceTypes } }
        : undefined,
    });

    // 4. Assemble context
    const context = this.assembleContext(searchResults);

    // 5. Generate answer
    const systemPrompt = this.getSystemPrompt();
    const { answer, usage } = await this.geminiService.chatWithContext(
      query,
      context,
      systemPrompt,
    );

    const result = {
      answer,
      sources: searchResults.map((r) => ({
        id: r.id,
        score: r.score,
        content: r.payload.content,
        metadata: r.payload.metadata,
      })),
      usage,
    };

    // 6. Cache result
    await this.cacheManager.set(cacheKey, result, 1800); // 30 ph√∫t

    return result;
  }

  // Specialized methods
  async chatFAQ(query: string): Promise<RAGSearchResult> {
    return this.query(query, { sourceTypes: ['faq'] });
  }

  async searchFacilities(query: string): Promise<RAGSearchResult> {
    return this.query(query, { sourceTypes: ['facility'] });
  }

  async searchSOPs(query: string): Promise<RAGSearchResult> {
    return this.query(query, { sourceTypes: ['sop', 'policy'] });
  }

  private assembleContext(results: any[]): string {
    // Format context t·ª´ search results
  }

  private getSystemPrompt(): string {
    return `
B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp TP.HCM (IUH), 
chuy√™n h·ªó tr·ª£ v·ªÅ qu·∫£n l√Ω c∆° s·ªü v·∫≠t ch·∫•t.

NHI·ªÜM V·ª§:
- Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin trong CONTEXT ƒë∆∞·ª£c cung c·∫•p
- N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, h√£y n√≥i r√µ v√† ƒë·ªÅ xu·∫•t li√™n h·ªá b·ªô ph·∫≠n h·ªó tr·ª£
- Gi·ªØ gi·ªçng ƒëi·ªáu th√¢n thi·ªán, chuy√™n nghi·ªáp
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát

CH√ö √ù:
- KH√îNG b·ªãa ƒë·∫∑t th√¥ng tin kh√¥ng c√≥ trong CONTEXT
- Tr√≠ch d·∫´n ngu·ªìn khi tr·∫£ l·ªùi
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y th·ª´a nh·∫≠n v√† ƒë∆∞a ra g·ª£i √Ω thay th·∫ø
    `.trim();
  }
}

interface RAGSearchResult {
  answer: string;
  sources: Array<{
    id: string;
    score: number;
    content: string;
    metadata: any;
  }>;
  usage: any;
}
```

---

## üè∑Ô∏è B∆Ø·ªöC 8: IMPLEMENT CLASSIFICATION SERVICE

**File: `src/ai/services/classification.service.ts`**

AI ph√¢n lo·∫°i s·ª± c·ªë t·ª± ƒë·ªông:

**Categories:**

- DIEN (ƒêi·ªán)
- NUOC (N∆∞·ªõc)
- MANG (M·∫°ng/Internet)
- NOI_THAT (N·ªôi th·∫•t)
- DIEU_HOA (ƒêi·ªÅu h√≤a)
- VE_SINH (V·ªá sinh)
- AN_NINH (An ninh)
- KHAC (Kh√°c)

**Priorities:**

- CRITICAL (Nguy hi·ªÉm, c·∫ßn x·ª≠ l√Ω g·∫•p)
- HIGH (Quan tr·ªçng)
- MEDIUM (Trung b√¨nh)
- LOW (Th·∫•p)

````typescript
@Injectable()
export class ClassificationService {
  constructor(
    private geminiService: GeminiService,
    @Inject(CACHE_MANAGER) private cacheManager: Cache,
  ) {}

  async classifyIncident(
    description: string,
    location?: string,
  ): Promise<ClassificationResult> {
    // T·∫°o prompt cho Gemini
    const prompt = this.buildClassificationPrompt(description, location);

    // Call Gemini v·ªõi temperature th·∫•p (0.2) ƒë·ªÉ consistent
    const response = await this.geminiService.chatCompletion(
      [{ role: 'user', content: prompt }],
      { temperature: 0.2, maxTokens: 500 },
    );

    // Parse JSON response
    const classification = JSON.parse(
      response.content.replace(/```json\n?|\n?```/g, '').trim(),
    );

    return {
      category: classification.category,
      priority: classification.priority,
      suggestedStaffSkills: classification.suggestedStaffSkills || [],
      estimatedDuration: classification.estimatedDuration || 60,
      reasoning: classification.reasoning,
      confidence: classification.confidence || 0.8,
    };
  }

  async suggestStaff(
    classification: ClassificationResult,
    availableStaff: any[],
  ): Promise<StaffSuggestion[]> {
    // AI ranking staff d·ª±a tr√™n skills, workload, location
  }

  private buildClassificationPrompt(
    description: string,
    location?: string,
  ): string {
    return `
B·∫°n l√† h·ªá th·ªëng AI ph√¢n lo·∫°i s·ª± c·ªë t·∫°i Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp TP.HCM.

M√î T√Å S·ª∞ C·ªê:
${description}

${location ? `ƒê·ªäA ƒêI·ªÇM: ${location}` : ''}

Y√äU C·∫¶U: Ph√¢n t√≠ch v√† tr·∫£ v·ªÅ JSON v·ªõi format:
{
  "category": "DIEN|NUOC|MANG|NOI_THAT|DIEU_HOA|VE_SINH|AN_NINH|KHAC",
  "priority": "CRITICAL|HIGH|MEDIUM|LOW",
  "suggestedStaffSkills": ["skill1", "skill2"],
  "estimatedDuration": 60,
  "reasoning": "L√Ω do ph√¢n lo·∫°i",
  "confidence": 0.85
}

H∆Ø·ªöNG D·∫™N PH√ÇN LO·∫†I:
- CRITICAL: Nguy hi·ªÉm t√≠nh m·∫°ng, ch√°y n·ªï, ƒëi·ªán gi·∫≠t, n∆∞·ªõc tr√†n l·ªõn
- HIGH: ·∫¢nh h∆∞·ªüng nhi·ªÅu ng∆∞·ªùi, ph√≤ng h·ªçc/ph√≤ng lab
- MEDIUM: ·∫¢nh h∆∞·ªüng √≠t ng∆∞·ªùi, kh√¥ng g·∫•p
- LOW: V·∫•n ƒë·ªÅ nh·ªè, kh√¥ng c·∫ßn x·ª≠ l√Ω ngay

CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG TH√äM TEXT KH√ÅC.
    `.trim();
  }
}

interface ClassificationResult {
  category: string;
  priority: string;
  suggestedStaffSkills: string[];
  estimatedDuration: number;
  reasoning: string;
  confidence: number;
}

interface StaffSuggestion {
  staffId: string;
  name: string;
  matchScore: number;
  reasons: string[];
}
````

---

## üì• B∆Ø·ªöC 9: IMPLEMENT INDEXING QUEUE

**File: `src/ai/queues/indexing.processor.ts`**

BullMQ worker x·ª≠ l√Ω indexing:

```typescript
@Processor('indexing')
export class IndexingProcessor {
  private readonly logger = new Logger(IndexingProcessor.name);

  constructor(
    private geminiService: GeminiService,
    private qdrantService: QdrantService,
    @InjectModel(IndexedDocument.name)
    private indexedDocModel: Model<IndexedDocument>,
  ) {}

  @Process('index-incident')
  async handleIndexIncident(job: Job) {
    const { vectorId, sourceType, sourceId, text, metadata } = job.data;

    try {
      // 1. Generate embedding
      this.logger.log(`Generating embedding for ${vectorId}...`);
      const embedding = await this.geminiService.generateEmbedding(text);

      // 2. Upsert v√†o Qdrant
      await this.qdrantService.upsertDocument(vectorId, embedding, {
        sourceType,
        sourceId,
        content: text.substring(0, 500), // L∆∞u preview
        ...metadata,
      });

      // 3. L∆∞u tracking v√†o MongoDB
      await this.indexedDocModel.findOneAndUpdate(
        { vectorId },
        {
          vectorId,
          sourceType,
          sourceId,
          content: text,
          metadata,
          embeddingDimension: 768,
          lastSyncedAt: new Date(),
          isActive: true,
        },
        { upsert: true },
      );

      this.logger.log(`‚úì Indexed ${vectorId} successfully`);

      return { success: true, vectorId };
    } catch (error) {
      this.logger.error(`‚úó Failed to index ${vectorId}:`, error);
      throw error; // BullMQ s·∫Ω retry
    }
  }

  @Process('batch-index')
  async handleBatchIndex(job: Job) {
    const { documents } = job.data; // Array of {vectorId, text, metadata}

    const texts = documents.map((d) => d.text);
    const embeddings = await this.geminiService.batchGenerateEmbeddings(texts);

    const points = documents.map((doc, i) => ({
      id: doc.vectorId,
      vector: embeddings[i],
      payload: {
        sourceType: doc.sourceType,
        content: doc.text.substring(0, 500),
        ...doc.metadata,
      },
    }));

    await this.qdrantService.batchUpsert(points);

    // Bulk insert v√†o MongoDB
    const operations = documents.map((doc, i) => ({
      updateOne: {
        filter: { vectorId: doc.vectorId },
        update: {
          $set: {
            vectorId: doc.vectorId,
            sourceType: doc.sourceType,
            sourceId: doc.sourceId,
            content: doc.text,
            metadata: doc.metadata,
            embeddingDimension: 768,
            lastSyncedAt: new Date(),
            isActive: true,
          },
        },
        upsert: true,
      },
    }));

    await this.indexedDocModel.bulkWrite(operations);

    return { success: true, count: documents.length };
  }
}
```

**File: `src/ai/queues/indexing.queue.ts`**

```typescript
@Injectable()
export class IndexingQueueService {
  constructor(@InjectQueue('indexing') private indexingQueue: Queue) {}

  async addIndexJob(data: {
    vectorId: string;
    sourceType: string;
    sourceId: string;
    text: string;
    metadata: any;
  }) {
    return this.indexingQueue.add('index-incident', data, {
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 2000,
      },
    });
  }

  async addBatchIndexJob(documents: any[]) {
    return this.indexingQueue.add(
      'batch-index',
      { documents },
      {
        attempts: 3,
        backoff: {
          type: 'exponential',
          delay: 5000,
        },
      },
    );
  }

  async getJobStatus(jobId: string) {
    const job = await this.indexingQueue.getJob(jobId);
    return {
      id: job.id,
      state: await job.getState(),
      progress: job.progress(),
      failedReason: job.failedReason,
    };
  }
}
```

---

## üåê B∆Ø·ªöC 10: IMPLEMENT CONTROLLERS

### **File: `src/ai/controllers/chat.controller.ts`**

```typescript
@Controller('ai/chat')
@UseGuards(JwtAuthGuard)
@UseInterceptors(CacheInterceptor)
export class ChatController {
  constructor(private ragService: RAGService) {}

  @Post()
  @UsePipes(new ValidationPipe())
  async chat(@Body() dto: ChatDto, @Request() req) {
    const result = await this.ragService.query(dto.query);

    return {
      success: true,
      data: {
        answer: result.answer,
        sources: result.sources,
        conversationId: dto.conversationId,
      },
      meta: {
        usage: result.usage,
        timestamp: new Date(),
        userId: req.user.id,
      },
    };
  }

  @Get('faq')
  async searchFAQ(@Query('q') query: string) {
    return this.ragService.chatFAQ(query);
  }

  @Get('facilities')
  async searchFacilities(@Query('q') query: string) {
    return this.ragService.searchFacilities(query);
  }

  @Get('sop')
  async searchSOPs(@Query('q') query: string) {
    return this.ragService.searchSOPs(query);
  }
}
```

**DTO: `src/ai/dtos/chat.dto.ts`**

```typescript
import { IsString, IsOptional, IsUUID, MinLength } from 'class-validator';

export class ChatDto {
  @IsString()
  @MinLength(3, { message: 'C√¢u h·ªèi ph·∫£i c√≥ √≠t nh·∫•t 3 k√Ω t·ª±' })
  query: string;

  @IsOptional()
  @IsUUID()
  conversationId?: string;
}
```

### **File: `src/ai/controllers/classification.controller.ts`**

```typescript
@Controller('ai/classify')
@UseGuards(JwtAuthGuard)
export class ClassificationController {
  constructor(
    private classificationService: ClassificationService,
    @InjectModel(Incident.name) private incidentModel: Model<Incident>,
  ) {}

  @Post('incident')
  async classifyIncident(@Body() dto: ClassifyIncidentDto) {
    const classification = await this.classificationService.classifyIncident(
      dto.description,
      dto.location,
    );

    return {
      success: true,
      data: classification,
    };
  }

  @Post('incident/:id/auto-classify')
  async autoClassifyAndUpdate(@Param('id') id: string) {
    const incident = await this.incidentModel.findById(id);
    if (!incident) {
      throw new NotFoundException('Incident not found');
    }

    const classification = await this.classificationService.classifyIncident(
      incident.description,
      incident.location,
    );

    // Update incident v·ªõi AI classification
    await this.incidentModel.updateOne(
      { _id: id },
      {
        $set: {
          category: classification.category,
          priority: classification.priority,
          aiMetadata: {
            ...classification,
            autoClassified: true,
            classifiedAt: new Date(),
          },
        },
      },
    );

    return {
      success: true,
      data: classification,
    };
  }

  @Post('suggest-
```
